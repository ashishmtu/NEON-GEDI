{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19daa3-c9a7-4724-8553-78dc2fbd6c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory containing the CSV files and the output file path\n",
    "directory_path = r'csv'  # Update this to your directory\n",
    "output_file_path = r'rh_distributed.csv'   # Path for the output CSV file\n",
    "\n",
    "# Function to find the elevation at which the given percentile of the cumulative amplitude is reached\n",
    "def find_elevation_at_percentile(df, cumulative_percentile):\n",
    "    row = df[df['Cumulative_Amplitude'] >= cumulative_percentile].iloc[0]\n",
    "    return row['Elevation']\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "rh_percentiles_results = []\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory_path, csv_file)\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Sort data by 'Elevation' in ascending order\n",
    "    sorted_data = data.sort_values(by='Elevation', ascending=True)\n",
    "\n",
    "    # Calculate cumulative sum normalized by its last element\n",
    "    sorted_data['Cumulative_Amplitude'] = sorted_data['Rxwaveform'].cumsum()\n",
    "    sorted_data['Cumulative_Amplitude'] /= sorted_data['Cumulative_Amplitude'].iloc[-1]\n",
    "\n",
    "    # Define the percentiles\n",
    "    percentiles = {'RH10': 0.10, 'RH20': 0.20, 'RH25': 0.25, 'RH30': 0.30, 'RH40': 0.40, 'RH50': 0.50, 'RH60': 0.60, 'RH70': 0.70, 'RH75': 0.75, 'RH80': 0.80, 'RH90': 0.90, 'RH95': 0.95, 'RH98': 0.98}\n",
    "    rh_values = [csv_file.replace('.csv', '')]  # Start with the file name (without .csv)\n",
    "    \n",
    "    for name, percentile in percentiles.items():\n",
    "        elevation = find_elevation_at_percentile(sorted_data, percentile)\n",
    "        rh_values.append(elevation)\n",
    "    \n",
    "    # Append the results\n",
    "    rh_percentiles_results.append(rh_values)\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "rh_percentiles_df = pd.DataFrame(rh_percentiles_results, columns=['FileName'] + list(percentiles.keys()))\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "rh_percentiles_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"RH percentiles calculated and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c949175-a5cf-43f5-9c12-0ff26a81f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rxwaveform  Amplitude_Percent  Elevation  Cumulative_Amplitude\n",
      "488    0.057138         100.000000   4.399994            100.000000\n",
      "489    0.057113          99.956428   4.249994            199.956428\n",
      "487    0.056678          99.194905   4.549994            299.151333\n",
      "490    0.056601          99.059913   4.099994            398.211246\n",
      "486    0.055751          97.572014   4.699994            495.783260\n",
      "491    0.055615          97.333364   3.949994            593.116623\n",
      "485    0.054386          95.182351   4.849994            688.298974\n",
      "492    0.054185          94.831032   3.799994            783.130006\n",
      "484    0.052620          92.093037   4.999994            875.223043\n",
      "493    0.052359          91.635929   3.649994            966.858972\n",
      "483    0.050499          88.380934   5.149994           1055.239906\n",
      "494    0.050195          87.848105   3.499994           1143.088011\n",
      "482    0.048071          84.130636   5.299994           1227.218647\n",
      "495    0.047767          83.598655   3.349994           1310.817302\n",
      "290    0.046367          81.148025  34.099997           1391.965328\n",
      "291    0.046277          80.991218  33.949997           1472.956546\n",
      "289    0.046234          80.916580  34.249997           1553.873125\n",
      "292    0.045984          80.478431  33.799997           1634.351556\n",
      "288    0.045874          80.286156  34.399997           1714.637712\n",
      "293    0.045521          79.668739  33.649996           1794.306451\n",
      "481    0.045384          79.428863   5.449994           1873.735314\n",
      "287    0.045295          79.271795  34.549997           1953.007109\n",
      "496    0.045156          79.029129   3.199994           2032.036238\n",
      "294    0.044930          78.634467  33.499996           2110.670705\n",
      "286    0.044521          77.918419  34.699997           2188.589124\n",
      "295    0.044254          77.451309  33.349996           2266.040433\n",
      "285    0.043588          76.285116  34.849997           2342.325549\n",
      "296    0.043532          76.186811  33.199996           2418.512359\n",
      "297    0.042793          74.893371  33.049996           2493.405730\n",
      "284    0.042537          74.445090  34.999997           2567.850820\n",
      "RH10: 5.29999423656295\n",
      "RH25: 32.7499964202254\n",
      "RH50: 0.0499938189225873\n",
      "RH75: 42.7999972197084\n",
      "RH90: 13.9999949286527\n",
      "RH95: 13.2499948689898\n",
      "RH98: 11.5999947377314\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file\n",
    "file_path = r\"ABBY_001_2017_D.las.csv\"  # Replace with the path to your actual CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Sort the DataFrame based on Amplitude_Percent in descending order\n",
    "sorted_data = data.sort_values(by='Amplitude_Percent', ascending=False)\n",
    "\n",
    "# Calculate the cumulative sum of Amplitude_Percent\n",
    "sorted_data['Cumulative_Amplitude'] = sorted_data['Amplitude_Percent'].cumsum()\n",
    "\n",
    "# Display the sorted data with cumulative sum to manually inspect\n",
    "print(sorted_data.head(30))  # You can adjust the number of rows to display as needed\n",
    "\n",
    "# Define a function to find the elevation at which the given percentile of the cumulative amplitude is reached\n",
    "def find_elevation_at_percentile(df, percentile):\n",
    "    threshold = df['Cumulative_Amplitude'].iloc[-1] * (percentile / 100.0)\n",
    "    return df[df['Cumulative_Amplitude'] >= threshold]['Elevation'].iloc[0]\n",
    "\n",
    "# Calculate and print the elevations for each percentile\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 98]\n",
    "for percentile in percentiles:\n",
    "    elevation = find_elevation_at_percentile(sorted_data, percentile)\n",
    "    print(f'RH{percentile}: {elevation}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba64bb0-80a1-405f-b33d-fcc837b50fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
